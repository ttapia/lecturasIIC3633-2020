# Performance of Recommender Algorithms on Top-N Recommendation Tasks

Este paper fue escrito por Cremonesi, P. et al. y fue publicado el año 2010. La premisa del paper es que los algoritmos de recomendación que tienen un buen rendimiento en métricas como RMSE o MAE no necesariamente tienen un buen rendimiento en tareas de recomendación de tipo top-N. Asimismo, se plantea que existe un sesgo que eleva el rendimiento de cualquier algoritmo al incorporar en su recomendación los ítems con mayor popularidad, por lo cual debe existir un mayor cuidado al momento de elegir el set de test. Finalmente, se plantean dos algoritmos que tienen un buen rendimiento en tareas de top-N, independiente del RMSE.

El paper comienza detallando la metodología de testeo, y desde un principio me llama la atención que indican que en el test-set sólo tienen ratings de 5 estrellas, lo cual suponen que las hace relevante para los usuarios respectivos. No se entra en detalle respecto a la tendencia que tiene cada usuario para sus ratings (usuarios optimistas v/s pesimistas), lo que me parece que también introduce un cierto sesgo al método.

Continuando, se explican los métodos clásicos de recomendación, con lo que se llega a la definición de un nuevo método que no apunta directamente a reducir el RMSE. Este método, llamado Non-normalized Cosine Neighborhood define una métrica de asociación de la siguiente forma:

![Fórmula de NNCosNgbr](https://i.imgur.com/95dUujT.png "NNCosNgbr")

Como su nombre lo dice, no está normalizado (se elimina el denominador), por lo que no representa un rating en sí, sino que representa la asociación entre el item i y el usuario u. Me parece muy ingeniosa la idea de quitar la normalización para otorgarle mayor peso a aquellos ítems en los que la similaridad encuentra una fuerte asociación. Claramente se apunta a fortalecer el rendimiento en tareas de top-N y no a predecir un rating específico dentro de un rango.

Luego, se define otro algoritmo (PureSVD) que, bajo el mismo principio de ignorar el rango original de ratings (1-5), se construye sobre la base de SVD. Considerando esto, la principal ventaja es que se pueden imputar valores fuera del rango original para los ratings faltantes de la matriz. Esto genera que el algoritmo sea mucho más eficiente computacionalmente y, según es mencionado, no afecta significativamente los resultados. No obstante, creo que se debería incluir (tal vez en algun anexo) algún detalle que demuestre que el resultado no cambia tanto (ya que no se presenta ningún sustento numérico que avale esta conclusión). Aun así, se plantea como un desafío para el trabajo futuro.

Finalmente, los resultados muestran que ambas métricas planteadas tienen un buen rendimiento, y especialmente PureSVD. Lo cual lleva a cuestionarse efectivamente si las métricas de error son buenas para las aplicaciones reales que pueden tener finalmente los sistemas recomendadores. Creo que el principal aporte de este paper es plantear esta discusión, para reevaluar los métodos utilizados en el área y enfocarse en los usos más prácticos. A fin de cuentas, pareciera que la tarea de predicción no se correlaciona tan bien con la de recomendación.
